go:
  data:
    kafka:
      servers: # 集群多个服务器之间重新一行,支持传入多个broker的ip:port
       - 192.168.20.130:9092
      consumer:
        commit_interval: 1 # 每隔多长时间自动commit一次offset。即一边读一边向kafka上报读到了哪个位置。
        group_id: recommend_biz # 一个Group内消费到的消息不会重复
        start_offset: first # first|last 当一个特定的partition没有commited offset时(比如第一次读一个partition，之前没有commit过)，通过StartOffset指定从第一个还是最后一个位置开始消费。StartOffset的取值要么是FirstOffset要么是LastOffset，LastOffset表示Consumer启动之前生成的老数据不管了。仅当指定了GroupID时，StartOffset才生效。
      producer:
        partition: hash # hash|round_robin 把message的key进行hash或者roundRobin，确定partition
        write_timeout: 1 # 设定写超时,秒
        required_acks: none # none|one|all RequireNone不需要等待ack返回，效率最高，安全性最低；RequireOne只需要确保Leader写入成功就可以发送下一条消息；RequiredAcks需要确保Leader和所有Follower都写入成功才可以发送下一条消息。
        allow_auto_topic_creation: true # Topic不存在时自动创建。生产环境中一般设为false，由运维管理员创建Topic并配置partition数目
        retry_count: 3 # 写入消息失败是，允许重试几次